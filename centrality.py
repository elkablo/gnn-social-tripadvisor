#!/usr/bin/env python3

import matplotlib.pyplot as plt
from mpl_toolkits.basemap import Basemap
import numpy as np
import networkx as nx
from networkx.algorithms.centrality import eigenvector_centrality
import argparse
from utils.data_reader import TripAdvisorDataReader
from utils.temporal import iter_months
from time import process_time

def is_temporal(G):
	'Returns True if graph was created with temporal_projection.py'
	return 'n_edges_by_date' in G.graph

def print_graph_info(G):
	other_node_type = 'hotels' if G.graph['nodes'] == 'authors' else 'authors'

	print(f'input graph of {len(G.nodes)} {G.graph["nodes"]} with {len(G.edges)} edges')
	print(f'- each node having at least {G.graph["min_reviews"]} reviews')
	print(f'- each node having at least {G.graph["min_neighbors"]} neighbors')
	print(f'- each edge representing at least {G.graph["min_common"]} common {other_node_type}')
	if 'max_year' in G.graph and G.graph['max_year'] is not None:
		print(f'- each review published at most in year {G.graph["max_year"]}')

	if is_temporal(G):
		min_date = G.graph['min_date']
		max_date = G.graph['max_date']
		print(f'- temporal projection with date range from {min_date[0]}/{min_date[1]:02d} to {max_date[0]}/{max_date[1]:02d}')

def dump_temporal_centralities(G, only_top=10):
	min_date = G.graph['min_date']
	max_date = G.graph['max_date']

	centralities = {}

	for date in iter_months(min_date, max_date):
		date_key = f'{date[0]}{date[1]:02d}'
		eigen_centr_key = f'ec_{date_key}'

		centralities[date] = {}

		for u in G.nodes:
			if eigen_centr_key in G.nodes[u]:
				centrality = G.nodes[u][eigen_centr_key]
			else:
				centrality = 0.0

			centralities[date][u] = centrality

	# print nodes in order of largest eigenvector centrality at the last date
	last = centralities[max_date]
	nodes = [ k for k, v in sorted(last.items(), key=lambda x: x[1], reverse=True) ]

	if only_top is not None or only_top <= 0:
		nodes = nodes[:only_top]

	for date in iter_months(min_date, max_date):
		print(f'{date[0]}/{date[1]:02d}', end='')
		for u in nodes:
			print(f'\t{centralities[date][u]:.08f}', end='')
		print('')

parser = argparse.ArgumentParser(description='Utility to compute / dump centralities on a TripAdvisor review graph projected to authors or hotels')
parser.add_argument('-i', '--input', type=str, required=True,
		    help='input graph file generated by projection.py or temporal_projection.py')
parser.add_argument('-o', '--output', type=str,
		    help='file to save the graph, with community information. If not given, will dump centralities.')
parser.add_argument('--dump-temporal-centralities', action='store_true',
		    help='dump temporal eigenvector centralities recorder in input file, nodes sorted by last date centralities')
parser.add_argument('--dump-temporal-centralities-only-best-n-nodes', type=int, metavar='N', default=10,
		    help='dump only the first N nodes with best eigenvector centralitities at the last date, 0 for all (default: 10)')

def main():
	args = parser.parse_args()

	G = nx.read_gpickle(args.input)

	print_graph_info(G)

	# dump temporal centralities and exit
	if args.dump_temporal_centralities:
		dump_temporal_centralities(G, args.dump_temporal_centralities_only_best_n_nodes)
		exit()

	print(f'computing centralities')

	eigen = eigenvector_centrality(G, max_iter=100, weight='w')

	# save graph with communities
	if args.output is not None:
		print(f'saving graph with centrality information to {args.output}')

		G.graph['centralities'] = 'eigen'
		nx.set_node_attributes(G, eigen, 'eigen')

		nx.write_gpickle(G, args.output)
	else:
		# sort by eigenvector centralities
		print('node\teigen')
		for key in sorted(eigen, key=lambda x: eigen[x], reverse=True):
			print(f'{key} {eigen[key]}')

if __name__ == '__main__':
	main()
